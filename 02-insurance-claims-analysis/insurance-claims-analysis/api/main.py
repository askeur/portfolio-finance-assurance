#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
API Flask pour l'Analyse d'Assurance
Int√®gre le preprocessing, mod√©lisation et pr√©dictions
"""

from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
import pandas as pd
import numpy as np
import os
import joblib
import io
import json
from datetime import datetime
import logging
from werkzeug.utils import secure_filename
import tempfile

# Importer nos modules personnalis√©s
from data_preparation import InsuranceDataPreprocessor
from model_training import InsuranceModelTrainer
from visualization import InsuranceDataVisualizer

# Configuration logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)

# Configuration
app.config['MAX_CONTENT_LENGTH'] = 100 * 1024 * 1024  # 100MB max
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['RESULTS_FOLDER'] = 'results'

# Cr√©er les dossiers n√©cessaires
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)
os.makedirs(app.config['RESULTS_FOLDER'], exist_ok=True)
os.makedirs('models', exist_ok=True)
os.makedirs('data/processed', exist_ok=True)
os.makedirs('reports/figures', exist_ok=True)

# Variables globales pour stocker les instances
preprocessor = None
trainer = None
visualizer = InsuranceDataVisualizer()

@app.route('/')
def home():
    """Page d'accueil de l'API"""
    return jsonify({
        "message": "üè• API d'Analyse d'Assurance",
        "version": "1.0.0",
        "endpoints": {
            "upload": "/upload - POST - Uploader des fichiers CSV",
            "preprocess": "/preprocess - POST - Pr√©processer les donn√©es",
            "train": "/train - POST - Entra√Æner les mod√®les",
            "predict": "/predict - POST - Faire des pr√©dictions",
            "visualize": "/visualize - GET - G√©n√©rer des visualisations",
            "status": "/status - GET - √âtat du syst√®me",
            "models": "/models - GET - Liste des mod√®les disponibles"
        }
    })

@app.route('/status')
def status():
    """√âtat du syst√®me"""
    global preprocessor, trainer
    
    models_available = []
    if os.path.exists('models'):
        models_available = [f for f in os.listdir('models') if f.endswith('.joblib')]
    
    processed_data_exists = os.path.exists('data/processed/processed_data.csv')
    
    return jsonify({
        "status": "‚úÖ Op√©rationnel",
        "timestamp": datetime.now().isoformat(),
        "components": {
            "preprocessor_loaded": preprocessor is not None,
            "trainer_loaded": trainer is not None,
            "processed_data_available": processed_data_exists,
            "models_count": len(models_available)
        },
        "available_models": models_available,
        "data_files": {
            "processed_data": processed_data_exists,
            "upload_folder": os.path.exists(app.config['UPLOAD_FOLDER'])
        }
    })

@app.route('/upload', methods=['POST'])
def upload_files():
    """Uploader des fichiers CSV"""
    try:
        if 'bene_file' not in request.files or 'claims_file' not in request.files:
            return jsonify({
                "error": "‚ùå Fichiers manquants. Requis: bene_file, claims_file"
            }), 400
        
        bene_file = request.files['bene_file']
        claims_file = request.files['claims_file']
        
        if bene_file.filename == '' or claims_file.filename == '':
            return jsonify({"error": "‚ùå Noms de fichiers vides"}), 400
        
        # Sauvegarder les fichiers
        bene_filename = secure_filename(bene_file.filename)
        claims_filename = secure_filename(claims_file.filename)
        
        bene_path = os.path.join(app.config['UPLOAD_FOLDER'], bene_filename)
        claims_path = os.path.join(app.config['UPLOAD_FOLDER'], claims_filename)
        
        bene_file.save(bene_path)
        claims_file.save(claims_path)
        
        # V√©rifier les fichiers
        try:
            bene_df = pd.read_csv(bene_path)
            claims_df = pd.read_csv(claims_path)
            
            return jsonify({
                "message": "‚úÖ Fichiers upload√©s avec succ√®s",
                "files": {
                    "bene_file": {
                        "filename": bene_filename,
                        "shape": bene_df.shape,
                        "columns": list(bene_df.columns)
                    },
                    "claims_file": {
                        "filename": claims_filename,
                        "shape": claims_df.shape,
                        "columns": list(claims_df.columns)
                    }
                }
            })
            
        except Exception as e:
            return jsonify({
                "error": f"‚ùå Erreur lors de la lecture des CSV: {str(e)}"
            }), 400
            
    except Exception as e:
        logger.error(f"Erreur upload: {str(e)}")
        return jsonify({"error": f"‚ùå Erreur upload: {str(e)}"}), 500

@app.route('/preprocess', methods=['POST'])
def preprocess_data():
    """Pr√©processer les donn√©es"""
    global preprocessor
    
    try:
        # R√©cup√©rer les param√®tres
        data = request.get_json() or {}
        bene_filename = data.get('bene_filename', 'bene_file.csv')
        claims_filename = data.get('claims_filename', 'Inpatient_Claim.csv')
        
        # Chemins des fichiers
        bene_path = os.path.join(app.config['UPLOAD_FOLDER'], bene_filename)
        claims_path = os.path.join(app.config['UPLOAD_FOLDER'], claims_filename)
        
        # V√©rifier que les fichiers existent
        if not os.path.exists(bene_path) or not os.path.exists(claims_path):
            return jsonify({
                "error": "‚ùå Fichiers non trouv√©s. Uploadez d'abord les fichiers."
            }), 400
        
        # Initialiser le preprocessor
        preprocessor = InsuranceDataPreprocessor()
        
        # Pipeline de preprocessing
        logger.info("D√©but du preprocessing...")
        
        # 1. Charger les donn√©es
        bene_df, claims_df = preprocessor.load_data(bene_path, claims_path)
        if bene_df is None or claims_df is None:
            return jsonify({"error": "‚ùå Erreur lors du chargement des donn√©es"}), 500
        
        # 2. Explorer les donn√©es
        exploration_stats = {
            "bene_shape": bene_df.shape,
            "claims_shape": claims_df.shape,
            "bene_columns": list(bene_df.columns),
            "claims_columns": list(claims_df.columns)
        }
        
        # 3. Fusionner les donn√©es
        merged_df = preprocessor.merge_data()
        
        # 4. Nettoyer les donn√©es
        cleaned_df = preprocessor.clean_data()
        
        # 5. Ing√©nierie des features
        feature_df = preprocessor.feature_engineering()
        
        # 6. Sauvegarder les donn√©es trait√©es
        preprocessor.save_processed_data()
        
        return jsonify({
            "message": "‚úÖ Preprocessing termin√© avec succ√®s",
            "results": {
                "original_data": exploration_stats,
                "merged_shape": merged_df.shape,
                "cleaned_shape": cleaned_df.shape,
                "final_shape": feature_df.shape,
                "final_columns": list(feature_df.columns),
                "processed_file": "data/processed/processed_data.csv"
            }
        })
        
    except Exception as e:
        logger.error(f"Erreur preprocessing: {str(e)}")
        return jsonify({
            "error": f"‚ùå Erreur preprocessing: {str(e)}"
        }), 500

@app.route('/train', methods=['POST'])
def train_models():
    """Entra√Æner les mod√®les"""
    global trainer
    
    try:
        # Param√®tres
        data = request.get_json() or {}
        model_types = data.get('model_types', ['classification', 'clustering'])
        optimize = data.get('optimize', True)
        
        # V√©rifier que les donn√©es pr√©process√©es existent
        processed_path = "data/processed/processed_data.csv"
        if not os.path.exists(processed_path):
            return jsonify({
                "error": "‚ùå Donn√©es pr√©process√©es non trouv√©es. Lancez d'abord le preprocessing."
            }), 400
        
        # Initialiser le trainer
        trainer = InsuranceModelTrainer()
        
        # Charger les donn√©es
        df = trainer.load_processed_data(processed_path)
        if df is None:
            return jsonify({"error": "‚ùå Erreur lors du chargement des donn√©es"}), 500
        
        results = {}
        
        # Pr√©parer les donn√©es pour l'entra√Ænement
        # Simuler une target pour la classification (√† adapter selon vos donn√©es)
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            # Cr√©er une target factice bas√©e sur des seuils
            target_col = numeric_cols[0]  # Premi√®re colonne num√©rique
            threshold = df[target_col].median()
            y = (df[target_col] > threshold).astype(int)
            X = df[numeric_cols].fillna(0)
            
            from sklearn.model_selection import train_test_split
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42
            )
        
        # Classification
        if 'classification' in model_types:
            trainer.setup_classification_models()
            classification_results = trainer.train_classification_models(
                X_train, X_test, y_train, y_test, optimize=optimize
            )
            results['classification'] = {
                "models_trained": len(classification_results),
                "models": list(classification_results.keys())
            }
        
        # Clustering
        if 'clustering' in model_types:
            trainer.setup_clustering_models()
            clustering_results = trainer.train_clustering_models(X, optimize=optimize)
            results['clustering'] = {
                "models_trained": len(clustering_results),
                "models": list(clustering_results.keys())
            }
        
        # √âvaluation et sauvegarde
        if 'classification' in model_types:
            comparison_df = trainer.evaluate_models(X_test, y_test)
            trainer.generate_detailed_report(X_test, y_test)
            results['best_model'] = trainer.best_model_name if hasattr(trainer, 'best_model_name') else None
        
        trainer.save_models()
        
        return jsonify({
            "message": "‚úÖ Entra√Ænement termin√© avec succ√®s",
            "results": results,
            "files_generated": {
                "models": "models/",
                "reports": "reports/"
            }
        })
        
    except Exception as e:
        logger.error(f"Erreur entra√Ænement: {str(e)}")
        return jsonify({
            "error": f"‚ùå Erreur entra√Ænement: {str(e)}"
        }), 500

@app.route('/predict', methods=['POST'])
def predict():
    """Faire des pr√©dictions"""
    global trainer
    
    try:
        # R√©cup√©rer les donn√©es
        data = request.get_json()
        if not data or 'features' not in data:
            return jsonify({
                "error": "‚ùå Donn√©es manquantes. Format requis: {'features': [[...]]}"
            }), 400
        
        # Charger le meilleur mod√®le si pas d√©j√† charg√©
        if trainer is None or not hasattr(trainer, 'best_model'):
            model_files = [f for f in os.listdir('models') if f.startswith('best_model_')]
            if not model_files:
                return jsonify({
                    "error": "‚ùå Aucun mod√®le entra√Æn√© trouv√©. Entra√Ænez d'abord un mod√®le."
                }), 400
            
            model_path = os.path.join('models', model_files[0])
            model = joblib.load(model_path)
            
            # Simuler un trainer pour les pr√©dictions
            trainer = InsuranceModelTrainer()
            trainer.best_model = model
        
        # Faire les pr√©dictions
        features = np.array(data['features'])
        predictions, probabilities = trainer.predict_new_data(features)
        
        result = {
            "predictions": predictions.tolist() if predictions is not None else None,
            "probabilities": probabilities.tolist() if probabilities is not None else None,
            "model_used": getattr(trainer, 'best_model_name', 'unknown'),
            "num_predictions": len(predictions) if predictions is not None else 0
        }
        
        return jsonify({
            "message": "‚úÖ Pr√©dictions g√©n√©r√©es",
            "results": result
        })
        
    except Exception as e:
        logger.error(f"Erreur pr√©diction: {str(e)}")
        return jsonify({
            "error": f"‚ùå Erreur pr√©diction: {str(e)}"
        }), 500

@app.route('/visualize', methods=['GET'])
def generate_visualizations():
    """G√©n√©rer les visualisations"""
    try:
        # V√©rifier que les donn√©es existent
        processed_path = "data/processed/processed_data.csv"
        if not os.path.exists(processed_path):
            return jsonify({
                "error": "‚ùå Donn√©es pr√©process√©es non trouv√©es"
            }), 400
        
        # G√©n√©rer les visualisations
        visualizer.visualize_insurance_data(
            processed_data_path=processed_path,
            output_dir="reports/figures"
        )
        
        # Lister les fichiers g√©n√©r√©s
        figures_dir = "reports/figures"
        generated_files = []
        if os.path.exists(figures_dir):
            generated_files = [f for f in os.listdir(figures_dir) if f.endswith('.png')]
        
        return jsonify({
            "message": "‚úÖ Visualisations g√©n√©r√©es",
            "files": generated_files,
            "location": figures_dir
        })
        
    except Exception as e:
        logger.error(f"Erreur visualisation: {str(e)}")
        return jsonify({
            "error": f"‚ùå Erreur visualisation: {str(e)}"
        }), 500

@app.route('/models')
def list_models():
    """Lister les mod√®les disponibles"""
    try:
        models_dir = 'models'
        model_files = []
        
        if os.path.exists(models_dir):
            for filename in os.listdir(models_dir):
                if filename.endswith('.joblib'):
                    filepath = os.path.join(models_dir, filename)
                    model_info = {
                        "filename": filename,
                        "size_mb": round(os.path.getsize(filepath) / (1024*1024), 2),
                        "modified": datetime.fromtimestamp(
                            os.path.getmtime(filepath)
                        ).isoformat()
                    }
                    model_files.append(model_info)
        
        return jsonify({
            "models": model_files,
            "count": len(model_files)
        })
        
    except Exception as e:
        return jsonify({
            "error": f"‚ùå Erreur listage mod√®les: {str(e)}"
        }), 500

@app.route('/download/<path:filename>')
def download_file(filename):
    """T√©l√©charger un fichier g√©n√©r√©"""
    try:
        # S√©curiser le chemin
        filename = secure_filename(filename)
        
        # Chercher dans les diff√©rents dossiers
        possible_paths = [
            os.path.join('reports/figures', filename),
            os.path.join('reports', filename),
            os.path.join('data/processed', filename),
            os.path.join('models', filename)
        ]
        
        for path in possible_paths:
            if os.path.exists(path):
                return send_file(path, as_attachment=True)
        
        return jsonify({"error": "‚ùå Fichier non trouv√©"}), 404
        
    except Exception as e:
        return jsonify({
            "error": f"‚ùå Erreur t√©l√©chargement: {str(e)}"
        }), 500

@app.errorhandler(413)
def too_large(e):
    return jsonify({"error": "‚ùå Fichier trop volumineux (max 100MB)"}), 413

@app.errorhandler(500)
def internal_error(e):
    return jsonify({"error": "‚ùå Erreur interne du serveur"}), 500

if __name__ == '__main__':
    print("üöÄ D√©marrage de l'API d'Analyse d'Assurance...")
    app.run(host='0.0.0.0', port=5000, debug=True)